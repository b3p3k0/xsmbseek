================================================================================
                        SMBSeek GUI Testing Guide
================================================================================

OVERVIEW
--------
This guide provides comprehensive testing procedures for the SMBSeek GUI 
application. It covers environment setup, multiple user skill levels, and 
core functionality validation with a focus on the "scan -> peep -> snag" 
workflow.

Target: Internal development team testing with real data
Database: /home/kevin/git/xsmbseek/backend/smbseek.db
Test Scans: Limited to "US" country code only

================================================================================
PART 1: ENVIRONMENT SETUP
================================================================================

1.1 PYTHON VIRTUAL ENVIRONMENT SETUP (Ubuntu 24.04.3)
-------------------------------------------------------

Step 1: Navigate to project directory
  cd /home/kevin/git/xsmbseek

Step 2: Create Python virtual environment
  python3 -m venv smbseek_test_env

Step 3: Activate virtual environment
  source smbseek_test_env/bin/activate

Step 4: Verify activation (prompt should show "(smbseek_test_env)")
  which python3
  # Should show: /home/kevin/git/xsmbseek/smbseek_test_env/bin/python3

Step 5: Install dependencies
  cd backend
  pip install -r requirements.txt

Step 6: Verify installation
  python3 -c "import shodan, smbprotocol, pyspnego; print('Dependencies OK')"

1.2 CONFIGURATION SETUP
------------------------

Step 1: Create backend configuration
  cd /home/kevin/git/xsmbseek/backend
  cp conf/config.json.example conf/config.json

Step 2: Edit configuration file
  nano conf/config.json
  
  Replace "YOUR_API_KEY_HERE" with valid Shodan API key
  Verify all other settings are acceptable (defaults should work)

Step 3: Verify database exists
  ls -la smbseek.db
  # Should show existing database file with recent timestamp

1.3 GUI STARTUP VERIFICATION
-----------------------------

Step 1: Navigate to GUI directory
  cd /home/kevin/git/xsmbseek/gui

Step 2: Start GUI application
  python3 main.py

Step 3: Verify startup success
  - Application window opens without errors
  - Dashboard displays with metric cards
  - Status bar shows database connection
  - No error messages or dialogs appear

If startup fails, document exact error messages and continue with available tests.

================================================================================
PART 2: USER TESTING WORKFLOWS
================================================================================

2.1 MANAGER TEST (Non-Technical Executive)
-------------------------------------------
Purpose: Validate tool usability for business decision makers
Time Estimate: 10-15 minutes

WORKFLOW:
Step 1: Open application (already running from setup)
Step 2: Examine dashboard - can you identify:
  - Total number of servers in database?
  - How many have security vulnerabilities?
  - Geographic distribution of servers?
  - When the last scan was performed?

Step 3: Click "View Details" on "Total Servers" card
Step 4: In server list that opens, can you:
  - Identify which servers are in your country?
  - Find servers with the most security risks?
  - Understand what the columns mean?

Step 5: Double-click any server entry
Step 6: Can you understand the detailed information shown?

SUCCESS CRITERIA:
- Can find key business metrics within 2 minutes
- Can navigate to detailed information without confusion  
- Information presented is comprehensible to non-technical user

2.2 NOVICE USER WORKFLOW
-------------------------
Purpose: Test learning curve and basic functionality
Time Estimate: 20-30 minutes

WORKFLOW:
Step 1: Dashboard Exploration
  - Examine each metric card on dashboard
  - Try clicking different elements to learn interface
  - Note which actions are discoverable vs. confusing

Step 2: Data Viewing
  - Click "View Details" on multiple metric cards
  - Try different filtering options in server list
  - Practice selecting and viewing individual server details

Step 3: Basic Scan Initiation
  - Click "Start Scan" button on dashboard
  - Configure scan for "US" country code  
  - Start scan and observe progress indicators
  - Cancel scan after a few minutes (don't complete full scan)

Step 4: Navigation Practice
  - Move between different windows
  - Close and reopen various dialogs
  - Return to main dashboard from sub-windows

SUCCESS CRITERIA:
- Can complete basic navigation without assistance
- Understands primary data types and metrics
- Can initiate scan process with minimal confusion

2.3 INTERMEDIATE USER WORKFLOW  
-------------------------------
Purpose: Test complete scan-to-analysis workflow
Time Estimate: 45-60 minutes

WORKFLOW:
Step 1: Pre-Scan Assessment
  - Review current database contents on dashboard
  - Export current server list for comparison
  - Note baseline metrics (total servers, vulnerabilities, etc.)

Step 2: Full Scan Execution
  - Initiate new scan for "US" country code
  - Monitor progress through all phases
  - Document any errors or unexpected behavior
  - Allow scan to complete fully

Step 3: Post-Scan Analysis
  - Compare new dashboard metrics to baseline
  - Verify new servers appear in database
  - Check that scan results match expected data types
  - Validate timestamps and metadata accuracy

Step 4: Detailed Investigation
  - Filter server list to show only recent discoveries
  - Examine detailed information for new servers
  - Test export functionality with filtered results
  - Try different sorting and filtering combinations

Step 5: Configuration Management  
  - Access configuration editor from scan dialog
  - Review current settings without changing them
  - Test that configuration interface works properly

SUCCESS CRITERIA:
- Complete end-to-end scan workflow successfully
- Data properly persisted and retrievable
- All major GUI components function correctly

2.4 EXPERT USER WORKFLOW
-------------------------
Purpose: Stress-test advanced features and edge cases  
Time Estimate: 60-90 minutes

WORKFLOW:
Step 1: Advanced Data Analysis
  - Test all filtering combinations in server list
  - Verify data consistency across different views
  - Check for data integrity issues or anomalies
  - Test edge cases (very old data, unusual formats, etc.)

Step 2: Error Condition Testing
  - Test behavior with invalid API key
  - Test network disruption during scan
  - Test concurrent scan attempts (should be prevented)
  - Test extremely large result sets if available

Step 3: Integration Verification
  - Verify GUI data matches backend database directly
  - Test that all recent UI improvements work consistently
  - Validate new double-click functionality thoroughly
  - Test window resizing and layout responsiveness

Step 4: Performance Assessment
  - Monitor resource usage during large operations
  - Test responsiveness with different data volumes
  - Evaluate performance of filtering and searching
  - Document any lag or performance bottlenecks

Step 5: Regression Testing
  - Verify all previously working functionality still works
  - Test that recent changes don't break existing features
  - Validate that error messages are helpful and accurate

SUCCESS CRITERIA:
- All advanced features work as documented
- No regressions in existing functionality
- Performance acceptable for intended use cases
- Robust error handling throughout

================================================================================
PART 3: SPECIFIC FEATURE TESTING  
================================================================================

3.1 RECENT WINDOW SIZING IMPROVEMENTS
--------------------------------------
Test each dialog/window for proper sizing:

Main Window:
- Should open at 800x600 by default
- All elements visible without scrolling
- Resizable to larger sizes properly

Scan Dialog:  
- Should open at 500x460
- All configuration options visible
- Buttons accessible without scrolling
- Can see full configuration file path

Configuration Editor:
- Should open at 800x700  
- All text editing area visible
- Buttons (Open/Save/Cancel) clearly visible with proper spacing
- No cramped or overlapping elements

Server List Browser:
- Should open at 1000x700
- Table headers and data fully visible
- Filter controls accessible
- Action buttons clearly visible

3.2 DOUBLE-CLICK FUNCTIONALITY
-------------------------------
In Server List Browser window:

Test 1: Single-click behavior
- Click once on server entry
- Verify row becomes highlighted/selected  
- Selection should persist until clicking elsewhere

Test 2: Double-click behavior
- Double-click on server entry
- Should show detailed server information popup
- Content should be identical to using "View Details" button
- No blank dialogs or errors

Test 3: Edge cases
- Double-click on header row (should do nothing)
- Double-click on empty area (should show appropriate message)
- Double-click multiple entries rapidly (should handle gracefully)

3.3 DASHBOARD INTERACTION TESTING
----------------------------------
Metric Cards:
- Click "View Details" button on each card - should work correctly
- Click elsewhere on card area - should do nothing (no errors)
- Verify no unwanted click zones around buttons

Data Accuracy:
- Compare dashboard metrics to actual database contents
- Verify all numbers update correctly after new scans
- Check that timestamps and status information accurate

================================================================================
PART 4: FEEDBACK SUBMISSION
================================================================================

After completing your testing workflow(s), please fill out the feedback 
template provided in "SMBSeek_Feedback_Template.txt".

You may submit feedback incrementally as you complete sections, or provide
comprehensive feedback after testing multiple workflows.

Focus on issues that impact productivity, functionality, or user experience
rather than minor cosmetic details.

================================================================================
TROUBLESHOOTING COMMON ISSUES
================================================================================

GUI Won't Start:
- Verify virtual environment is activated
- Check that all dependencies installed correctly  
- Look for Python path or import errors in console

Scan Fails to Start:
- Verify Shodan API key is valid and configured
- Check network connectivity
- Ensure no other scans are running (lock file exists)

Database Issues:
- Verify smbseek.db file exists and is readable
- Check that backend path configuration is correct
- Look for permission or file corruption issues

Performance Problems:
- Monitor system resources during testing
- Note if specific operations cause delays
- Document any unresponsive or laggy behavior

================================================================================
END OF TESTING GUIDE
================================================================================